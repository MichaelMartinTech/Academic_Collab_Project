{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440f038-36a8-4668-a975-cf189d8dcc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from file...\n"
     ]
    }
   ],
   "source": [
    "#%run AcademicCollabProject.py\n",
    "\n",
    "from src.preprocessing import build_author_graph\n",
    "from src.features import extract_features_from_graph\n",
    "from src.model import train_model, evaluate_model, explain_model\n",
    "from src.visualize import draw_collab_graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Baseline models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_baseline_models(X_train, X_test, y_train, y_test, output_path=\"baseline_results.txt\"):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"SVM\": SVC(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier()\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in models.items():\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        minutes, seconds = divmod(elapsed, 60)\n",
    "        print(f\"Training time: {int(minutes):02d}:{int(seconds):02d}\")\n",
    "    \n",
    "        report = classification_report(y_test, preds)\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(report)\n",
    "        results.append(f\"=== {name} ===\\n{report}\\n\")\n",
    "\n",
    "    # Save all results to a text file\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.writelines(results)\n",
    "\n",
    "    print(f\"\\nBaseline model results saved to {output_path}\")\n",
    "\n",
    "import os\n",
    "import pickle # For saving/loading graphs\n",
    "\n",
    "\"\"\"\n",
    "Focus on:\n",
    "- Academic collaboration patterns\n",
    "- Coauthorship, citation impact, publication behavior\n",
    "- Classifying strong vs. weak collaborations\n",
    "\n",
    "All of this can be modeled in a single unified author graph.\n",
    "- No need to separate papers, authors, and fields into distinct .pk graphs unless doing:\n",
    "- Multi-type message passing (e.g., with heterogeneous GNNs)\n",
    "- Explicit field-level domain training\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    raw_data_dir = os.path.join(\"data\", \"raw\")\n",
    "    graph_cache = os.path.join(\"data\", \"author_graph.gpickle\")\n",
    "    model_path = \"randomforest_model.pkl\"\n",
    "    vis_path = \"top_authors_graph.png\"\n",
    "\n",
    "    import time\n",
    "    # Load or build graph with timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    G = None\n",
    "    \n",
    "    if os.path.exists(graph_cache):\n",
    "        print(\"Loading graph from file...\")\n",
    "        with open(graph_cache, \"rb\") as f:\n",
    "            G = pickle.load(f)\n",
    "        print(\"Graph loaded from cache.\")\n",
    "    else:\n",
    "        print(\"Building author collaboration graph...\")\n",
    "\n",
    "        papers_file = os.path.join(raw_data_dir, \"Papers_CS_20190919.tsv\")\n",
    "        authors_file = os.path.join(raw_data_dir, \"PAuAf_CS_20190919.tsv\")\n",
    "        citations_file = os.path.join(raw_data_dir, \"PR_CS_20190919.tsv\")\n",
    "        G = build_author_graph(papers_file, authors_file, citations_file)\n",
    "        with open(graph_cache, \"wb\") as f:\n",
    "            pickle.dump(G, f)\n",
    "        print(\"Graph saved to:\", graph_cache)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(f\"Graph ready in (hh:mm:ss) {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\")\n",
    "\n",
    "    # Visualize\n",
    "    print(\"Visualizing coauthor network...\")\n",
    "    if os.path.exists(vis_path):\n",
    "        resp = input(f\"Visualization already exists: {vis_path}\\nDo you want to overwrite it? (y/n): \").strip().lower()\n",
    "        if resp != \"y\":\n",
    "            print(\"[User Prompt - Skipped visualization.]\")\n",
    "        else:\n",
    "            draw_collab_graph(G, max_nodes=100, save_path=vis_path)\n",
    "    else:\n",
    "        draw_collab_graph(G, max_nodes=100, save_path=vis_path)\n",
    "\n",
    "    # Feature extraction\n",
    "    print(\"Extracting features for ML...\")\n",
    "    X, y = extract_features_from_graph(G)\n",
    "    print(f\"{len(X)} collaboration pairs extracted.\")\n",
    "\n",
    "    # Split data\n",
    "    print(\"Splitting data into train and test sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Prompt for model choice\n",
    "    choice = input(\"Train model or test an existing one? (train/test): \").strip().lower()\n",
    "\n",
    "    if choice == \"test\" and os.path.exists(model_path):\n",
    "        model = load_model(model_path)\n",
    "        print(\"Evaluating model on test data...\")\n",
    "        evaluate_model(model, X_test, y_test)\n",
    "        print(\"Explaining model via SHAP...\")\n",
    "        explain_model(model, X_test)\n",
    "    elif choice == \"train\":\n",
    "        print(\"Training will begin...\")\n",
    "    else:\n",
    "        print(f\"Model file not found at {model_path}.\")\n",
    "        retry = input(\"Would you like to train the model instead? (y/n): \").strip().lower()\n",
    "        if retry == \"y\":\n",
    "            choice = \"train\"\n",
    "        else:\n",
    "            print(\"Exiting. No model to test.\")\n",
    "            return\n",
    "\n",
    "    # If retrain is picked\n",
    "    if choice == \"train\":\n",
    "        print(\"Training model...\")\n",
    "        model = train_model(X_train, y_train)\n",
    "        save_model(model, model_path)\n",
    "\n",
    "        print(\"Evaluating model on test data...\")\n",
    "        evaluate_model(model, X_test, y_test)\n",
    "\n",
    "        print(\"Explaining model via SHAP...\")\n",
    "        explain_model(model, X_test)\n",
    "\n",
    "        # Baseline comparison\n",
    "        print(\"Running baseline models for comparison...\")\n",
    "        run_baseline_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    #Kmeans\n",
    "    from src.kmeans_model import run_kmeans\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Run KMeans after feature extraction\n",
    "    kmeans, cluster_labels = run_kmeans(X, n_clusters=2)\n",
    "    \n",
    "    # Compare with RF predictions\n",
    "    rf_preds = model.predict(X)\n",
    "    cm = confusion_matrix(rf_preds, cluster_labels)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"KMeans Cluster\")\n",
    "    plt.ylabel(\"RandomForest Prediction\")\n",
    "    plt.title(\"RF vs KMeans Confusion Matrix\")\n",
    "    plt.savefig(\"rf_vs_kmeans_confusion.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ec04b-14fe-407a-8b14-3eeef9bce44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
